################################################
## Calibration of the Church Censorship Model
## Authors: Blasutto blasutto and David de la Croix
################################################

## remove (almost) everything in the working environment.
rm(list = ls())

#increase memory size
memory.limit(size=50000)

# to import xl files
library(readxl)

#to write excel files
require(writexl)

# to output towards latex
require(stargazer)

# for generating random variables
library(evd)

# for latex symbols in the graphs
library(latex2exp)

# genetic algorithm for estimation
library(GA)

# for a bootstraped CI
library(boot)


################################################
# PART 1: GET THE DATA
################################################

# set the directory to where the files are located
#setwd("C:\\Users\\ddlc\\Documents\\Dropbox\\01. Research\\UTHC main\\access database")
setwd("C:\\Users\\Fabio\\Dropbox\\Roman_Church_censorship_growth\\big base\\old")

#load database 
basew <- as.data.frame(read_excel("dictionary2.xlsx"))
basetot <- as.data.frame(read_excel("Profs.xlsx"))
membersa  <- as.data.frame(read_excel("Italian academies.xlsx"))
membersu  <- as.data.frame(read_excel("Italian universities.xlsx"))

members<-rbind(membersa,membersu)

#setwd("C:\\Users\\ddlc\\Documents\\Dropbox\\01. Research\\Roman_Church_censorship_growth\\data_work")
setwd("C:\\Users\\Fabio\\Dropbox\\Roman_Church_censorship_growth\\data_work")

#removing people without worldcat
members <- members[members$Worldcat!="NA",]

#removing people not yet checked
members <- members[members$Forbidden!=8888,]

# computing a ref date and removing people without dates
members$refdatel <- pmin(members$Beginning,members$DateApprox-5,
                         members$YearBorn+30,members$End,members$YearDied,na.rm=T)
members<- members[!is.na(members$refdatel),]


#remove duplicates
members  <- members[!duplicated(members$Persons_PKey), ]
basew  <- basew[!duplicated(basew), ]
#members  <- members[!members$IKey=="AcadTurin-1757",]
members  <- members[members$refdatel>1400,]
members  <- members[!members$refdatel>1750,]
plist<-members$Persons_PKey
#Find the performance in the base generated by the wiki routine

# take the index of quality
members$perfl <- 0
basew$public<- basew$publications
#basew.pca <- prcomp(basew[,3:12], center = TRUE,scale. = TRUE)
for (j in plist){
  members[members$Persons_PKey==j,"perfl"] <- log(max(c(basew[basew$PKey==j,"public"],1)))  # for individual quality
  #members[members$Persons_PKey==j,"perfl"] <- log(basew.pca$x[j,1])
}


members<-members[!is.na(members$perfl),]

################################################
# PART 2: COMPUTE THE MOMENTS
################################################

#We consider 4 periods here
threshold0<- min(members$refdatel)
threshold1 <- round(quantile(members$refdatel,1/4),0)[[1]]
threshold2 <- round(quantile(members$refdatel,1/2),0)[[1]]
threshold3 <- round(quantile(members$refdatel,3/4),0)[[1]]
threshold4<-max(members$refdatel)


members1 <- members[members$refdatel<threshold1,]
members2 <- members[threshold2>members$refdatel & members$refdatel>=threshold1,]
members3 <- members[threshold3>members$refdatel & members$refdatel>=threshold2,]
members4 <- members[members$refdatel>=threshold3,]


memberscensored1 <- members[members$Forbidden<9999 & members$refdatel<threshold1,]
membersnotcensored1 <- members[members$Forbidden==9999 & members$refdatel<threshold1,]

memberscensored2 <- members[members$Forbidden<9999 & 
                              threshold2>members$refdatel & members$refdatel>=threshold1,]
membersnotcensored2 <- members[members$Forbidden==9999 &
                                 threshold2>members$refdatel & members$refdatel>=threshold1,]

memberscensored3 <- members[members$Forbidden<9999 &
                              threshold3>members$refdatel & members$refdatel>=threshold2,]
membersnotcensored3 <- members[members$Forbidden==9999 &
                                 threshold3>members$refdatel & members$refdatel>=threshold2,]

memberscensored4 <- members[members$Forbidden<9999 & members$refdatel>=threshold3,]
membersnotcensored4 <- members[members$Forbidden==9999 & members$refdatel>=threshold3,]


memberscensored <- members[members$Forbidden<9999 ,]
membersnotcensored <- members[members$Forbidden==9999 ,]

maxperf<-round(max(members$perfl)+0.5,)
maxpeople<-100/2

maxperfd <- 2* maxperf

bv<-(0:maxperfd)
bv<-bv/2


# get the k_t,K^theta_R and m_t*beta_t in the data
Embeta<-numeric(length=4)
Eqr<-numeric(length=4)
ENC<-numeric(length=4)
Eqc<-numeric(length=4)
Eq<-numeric(length=4)
Em<-numeric(length=4)

for (i in 1:4) {
  
  nam <- paste("members", i, sep = "")
  namc <- paste("memberscensored", i, sep = "")
  namnc <- paste("membersnotcensored", i, sep = "")
  
  Embeta[i]<-length(get(namc)$perfl)/(length(get(namc)$perfl)+ length(get(namnc)$perfl))
  Eqr[i]=mean(get(namc)$perfl)
  ENC[i]=mean(get(namnc)$perfl)
  Eq[i]=mean(get(nam)$perfl)
  
  
}
rm(nam,namc,namnc)

# get the variance of uality in the first period to get theta
Evar<-var(members1$perfl)

################################################
# PART 3: ACTUAL CALIBRATION+ESTIMATION
################################################

# calibrate theta to get match the variance of the overall distribution of quality

# create the all possible values for theta
m=100 #how fine is the grid for getting theta
theta_grid<-seq(0.1, 0.499, length.out=m)

# create the respective values for m and k_C^theta through bootstrapping
x=numeric()
k=numeric()
the=numeric()
pr<-numeric()
beta=numeric()
maxx<-100


# finally get theta that minimize the distance with empirical variance
var_thetap<-(Eq[1]/(gamma(1-theta_grid)))*(gamma(1-2*theta_grid)-gamma(1-theta_grid)^2)
dist=abs(var_thetap-var(memberscensored1$perfl))
theta=theta_grid[which.min(dist)]


# do a graph to visualize the fit
maxperf<-round(max(members$perfl)+0.5,)
maxpeople<-100/2
maxperfd <- 2* maxperf
bv<-(0:maxperfd)
bv<-bv/2


# setwd("C:\\Users\\blasutto\\Dropbox\\Roman_Church_censorship_growth\\calibration")
setwd("C:\\Users\\Fabio\\Dropbox\\Roman_Church_censorship_growth\\calibration")

pdf(file="fit_censored.pdf", width = 10, height = 5)
hist(memberscensored1$perfl,xlim=c(0,maxperf),ylim=c(0,0.5),prob=TRUE,col="gray",breaks=bv,
     main=paste("Histogram of scientific output per person ",threshold0," - ",threshold1),
     sub="Censored people only",
     xlab="log notoriety",ylab="probability")
curve(dfrechet(x, loc=0, scale=Eqr[1], shape=1/theta), 
      col="darkgray",add=TRUE,xlim=c(0,maxperf),ylim=c(0,0.5),lwd=4)
dev.off()


####################################################
# Here I proceed with the estimation
##################################################

t<-numeric()
v<-numeric()
pe<-numeric()
z0<-numeric()
up<-numeric()
Sqc<-numeric(length=4)
Sqr<-numeric(length=4)
SNC<-numeric(length=4)
Sq<-numeric(length=4)
pre<-numeric()
pre1<-numeric()
pre2<-numeric()
i<-numeric()
# match initial conditions
Sqr[1]=Eqr[1]
Sq[1]=Eq[1]

# some functions to get the simulated variables
w<-1
f<-function(x,the,k,pr) {
  
  -Eq[k]+(((Eqr[k]/x)^(1/the))/((Eqr[k]/x)^(1/the)+pr))*Eqr[k]+
    (1-(((Eqr[k]/x)^(1/the))/((Eqr[k]/x)^(1/the)+pr)))*x}


f1<-function(x,the,k,pr,bets) {
  
  -Eq[k]+(((Eqr[k]/x)^(1/the))/((Eqr[k]/x)^(1/the)+pr))*
    (Eqr[k]-(1-bets*(((Eqr[k]/x)^(1/the))/((Eqr[k]/x)^(1/the)+pr)))*ENC(k))/(1+bets)+
    (1-(((Eqr[k]/x)^(1/the))/((Eqr[k]/x)^(1/the)+pr)))*x}

zt<-function(beta,pe,t,up) {
  
  # get z0 first
  v=uniroot(f,c(0.00001,up),tol=0.00000001,maxiter=10000,the=theta,k=1,pr=pe)
  z0=(Eqr[1]/v$root)^(1/theta)
  if(t>=2){z0*((w^2*z0*(1-beta)/pe))^(-1+2^(t-1))}else{z0}}

mt<-function(beta,pr,t,up) zt(beta,pr,t,up)/(pr+zt(beta,pr,t,up))

mbetat<-function(beta,pr,t,up) beta*mt(beta,pr,t,up)

qrs<-function(beta,pe,t,up,mu,pre) gamma(1-theta)*(mu*w*((1-beta)*(pre/gamma(1-theta))^(1/theta)*
                                                         (mt(beta,pe,t-1,up))))^theta


qcs<-function(beta,pe,t,up,mu,pre) gamma(1-theta)*((mu*((pre/gamma(1-theta))^(1/theta)*
                                                          (1-mt(beta,pe,t-1,up)))))^theta


qs<-function(beta,pe,t,up,mu,pre1,pre2) qrs(beta,pe,t,up,mu,pre1)*mt(beta,pe,t,up)+
  (1-mt(beta,pe,t,up))*qcs(beta,pe,t,up,mu,pre2)

nc<-function(beta,pe,t,up,mu,pre1,pre2) qrs(beta,pe,t,up,mu,pre1)*
  (((1-beta)*mt(beta,pe,t,up))/(1-beta*mt(beta,pe,t,up)))+
  ((1-mt(beta,pe,t,up))/(1-beta*mt(beta,pe,t,up)))*
  qcs(beta,pe,t,up,mu,pre2)


#GUARDA A INITIAL CONDITION CIU C

# define the function that we want to minimize taking beta
maxg<-1000
max<-numeric()
maxx<-numeric()
muu<-numeric()
betaa<-numeric()
sum<-numeric(length=1)
upper<-seq(0.01,200,length.out=maxg)

mini<-function(betaa,pe,muu){
  
  # first check that I can find a Kc that rationalize data with
  # current parameter
  for(j in maxg:1){
    
    if(f(0.00001,theta,1,pe)*f(upper[j],theta,1,pe)<0){
      
      maxx=upper[j]
      break}
    
    maxx=400}
  
  # compute tha loss function
  if(f(0.00001,theta,1,pe)*f(maxx,theta,1,pe)>0){return(10000)}
  
  # get Sqc[1],Eqc[1] consistent with parameters
  v=uniroot(f,c(0.00001,maxx),tol=0.00000001,maxiter=10000,the=theta,k=1,pr=pe)
  Eqc[1]<-v$root
  
  
  for(i in 1:4){
    if(i>=2){
      Sqc[i]<-qcs(betaa,pe,i,maxx,muu,Sqc[i-1])
      Sqr[i]<-qrs(betaa,pe,i,maxx,muu,Sqr[i-1])
      Sq[i] <-qs(betaa,pe,i,maxx,muu,Sqr[i-1],Sqc[i-1])
      SNC[i]<-nc(betaa,pe,i,maxx,muu,Sqr[i-1],Sqc[i-1])
      
      
      
      
    }else{
      
      Eqc[1]<-v$root
      Sqc[1]<-Eqc[1]
      Sqr[1]<-Eqr[1]
      SNC[1]<-Eqr[1]*
        (((1-betaa)*mt(betaa,pe,1,maxx))/(1-betaa*mt(betaa,pe,1,maxx)))+
        ((1-mt(betaa,pe,1,maxx))/(1-betaa*mt(betaa,pe,1,maxx)))*
        Eqc[1]}
    
  }
  
  sum=0
  for (i in 1:4){
    mcur<-mt(betaa,pe,i,maxx)        
  #  sum=sum+((mcur*betaa-Embeta[i])/Embeta[i])^2
    if(i>=2){
      sum=sum+((qrs(betaa,pe,i,maxx,muu,Sqr[i-1])-Eqr[i])/Eqr[i])^2
      sum=sum+((qs(betaa,pe,i,maxx,muu,Sqr[i-1],Sqc[i-1])-Eq[i])/Eq[i])^2
      sum=sum+((nc(betaa,pe,i,maxx,muu,Sqr[i-1],Sqc[i-1])-ENC[i])/ENC[i])^2}
  }
  
  
  return(sum)}

ff<-function(x) -mini(x[1],x[2],x[3])
# call the genetic alogorithm for the estimation
GA <- ga(type = "real-valued", 
         fitness = ff, 
         lower = c(0,0.1,0.1),
         upper = c(0.99,750,55),
         popSize = 200, maxiter = 80, run = 40,
         pcrossover = 0.8,
         keepBest = TRUE,
         optim=TRUE,
         optimArgs = list(method = "L-BFGS-B",poptim = 0.2,pressel = 0.1,
                          control = list(fnscale = -1, maxit = 20)))

# visualize the solution 
summary(GA)
plot(GA)

beta<-GA@solution[1,1]
p<-GA@solution[1,2]
mu<-GA@solution[1,3]
print(mini(beta,p,mu))
print(Sqc)
print(Sq)


# compute empirical and non empirical
Smbeta=numeric(length=4)
Sz=numeric(length=4)
Sm=numeric(length=4)
Ez=numeric(length=4)
Em=numeric(length=4)

for(j in maxg:1){
  
  #  if(f(0.001,theta,1,p)*f(upper[j],theta,1,p)<0 & f(0.001,theta,2,p)*f(upper[j],theta,2,p)<0 &
  # f(0.001,theta,3,p)*f(upper[j],theta,3,p)<0 & f(0.001,theta,4,p)*f(upper[j],theta,4,p)<0){
  if(f(0.00001,theta,1,p)*f(upper[j],theta,1,p)<0){
    max=upper[j]
    break}}



for(i in 1:4){
  
  Sm[i]=mt(beta,p,i,max)
  Sz[i]=zt(beta,p,i,max)
  Smbeta[i]=mbetat(beta,p,i,max)
  
  #v=uniroot(f,c(0.00001,max),tol=0.0001,maxiter=100,the=theta,k=i,pr=p)
  #Eqc[i]=v$root
  v=uniroot(f,c(0.00001,max),tol=0.0001,maxiter=100,the=theta,k=1,pr=p)
  Eqc[1]=v$root
  Ez[i]=(Eqr[i]/Eqc[i])^(1/theta)
  Em[i]=Ez[i]/(p+Ez[i])
  
  if(i>=2){
    
    Sqc[i]=qcs(beta,p,i,max,mu,Sqc[i-1])
    Sqr[i]=qrs(beta,p,i,max,mu,Sqr[i-1])
    Sq[i]=qs(beta,p,i,max,mu,Sqr[i-1],Sqc[i-1])
    SNC[i]=nc(beta,p,i,max,mu,Sqr[i-1],Sqc[i-1])
  }else{
    
    Sqc[1]=Eqc[1]
    Sq[1]=Eq[1]
    SNC[1]=Eqr[1]*
      (((1-beta)*mt(beta,p,1,max))/(1-beta*mt(beta,p,1,max)))+
      ((1-mt(beta,p,1,max))/(1-beta*mt(beta,p,1,max)))*
      Eqc[1]
    Sqr[1]=Eqr[1]}}

##################################
# get bootstraped CI for graph
##################################
ns<-length(members$perfl)
nboots<-100
boots<-numeric(ns)
Bmbeta<-array(,c(4,nboots))
Bq<-array(,c(4,nboots))
BNC<-array(,c(4,nboots))
Bqr<-array(,c(4,nboots))
rm(.Random.seed, envir=globalenv())
#aa<-replicate(nboots, sample(members, ns,replace=TRUE))
for(i in 1:nboots){
  
  
  boots<-as.data.frame(sample(members$Persons_PKey,ns,replace=TRUE))
  memb<-merge(boots,members,
              by.x='sample(members$Persons_PKey, ns, replace = TRUE)',
              by.y='Persons_PKey')
  
  # compute what we need
  #memb<-members[boots%in% members$Persons_PKey]
  #memb<-subset(members,members$Persons_PKey==boots)
  
  #We consider 4 periods here
  members1 <- memb[memb$refdatel<threshold1,]
  members2 <- memb[threshold2>memb$refdatel & memb$refdatel>=threshold1,]
  members3 <- memb[threshold3>memb$refdatel & memb$refdatel>=threshold2,]
  members4 <- memb[memb$refdatel>=threshold3,]
  
  
  memberscensored1 <- memb[memb$Forbidden<9999 & memb$refdatel<threshold1,]
  membersnotcensored1 <- memb[memb$Forbidden==9999 & memb$refdatel<threshold1,]
  
  memberscensored2 <- memb[memb$Forbidden<9999 &
                             threshold2>memb$refdatel & memb$refdatel>=threshold1,]
  membersnotcensored2 <- memb[memb$Forbidden==9999 &
                                threshold2>memb$refdatel & memb$refdatel>=threshold1,]
  
  memberscensored3 <- memb[memb$Forbidden<9999 &
                             threshold3>memb$refdatel & memb$refdatel>=threshold2,]
  membersnotcensored3 <- memb[memb$Forbidden==9999 &
                                threshold3>memb$refdatel & memb$refdatel>=threshold2,]
  
  memberscensored4 <- memb[memb$Forbidden<9999 & memb$refdatel>=threshold3,]
  membersnotcensored4 <- memb[memb$Forbidden==9999 & memb$refdatel>=threshold3,]
  
  memberscensored <- memb[memb$Forbidden<9999 ,]
  
  #the moments now
  for(j in 1:4){
    
    nam <- paste("members", j, sep = "")
    namc <- paste("memberscensored", j, sep = "")
    namnc <- paste("membersnotcensored", j, sep = "")
    
    Bmbeta[j,i]<-length(get(namc)$perfl)/(length(get(namc)$perfl)+ length(get(namnc)$perfl))
    Bqr[j,i]=mean(get(namc)$perfl)
    Bq[j,i]=mean(get(nam)$perfl)
    BNC[j,i]=mean(get(namnc)$perfl)}}

#get finally the CI
CImbeta<-array(,c(2,4))
CIq<-array(,c(2,4))
CIqr<-array(,c(2,4))
CINC<-array(,c(2,4))

for(j in 1:4){
  CImbeta[,j]<-quantile(Bmbeta[j,],c(0.025,0.975))
  CIq[,j]<-quantile(Bq[j,],c(0.025,0.975))
  CIqr[,j]<-quantile(Bqr[j,],c(0.025,0.975))
  CINC[,j]<-quantile(BNC[j,],c(0.025,0.975))}




#################################
# graph to visualize the reults
#################################

# function for more than one title per graph
line2user <- function(line, side) {
  lh <- par('cin')[2] * par('cex') * par('lheight')
  x_off <- diff(grconvertX(0:1, 'inches', 'user'))
  y_off <- diff(grconvertY(0:1, 'inches', 'user'))
  switch(side,
         `1` = par('usr')[3] - line * y_off * lh,
         `2` = par('usr')[1] - line * x_off * lh,
         `3` = par('usr')[4] + line * y_off * lh,
         `4` = par('usr')[2] + line * x_off * lh,
         stop("side must be 1, 2, 3, or 4", call.=FALSE))
}

# set up something about the graph
time=seq(1,4,1) 
timee=c(paste(threshold0,'-',threshold1),
        paste(threshold1,'-',threshold2),
        paste(threshold2,'-',threshold3),
        paste(threshold3,'-',threshold4))
pc <- c("grey40","red","grey83")
pdf(file="fit.pdf", width = 10, height = 10)
par(mfrow=c(2,2),oma = c(3, 1, 1, 1),
    mgp=c(2,0.3,0)) # all plots on one page 


#q
xrange <- range(time)
yrange <- c(0,min(max(Eq,Sq),200))
plot(xrange,yrange,type="n", xlab="Time",
     ylab=TeX('$q_t$'),cex.lab=1.6,xaxt='n')
axis(1, at=1:4,labels=timee,font=2)
polygon(c(time,rev(time)),c(CIq[1,],rev(CIq[2,])),col =pc[3], border = FALSE,axes=F)
lines(time,Eq,type="l",col=pc[1],lwd=3,axes=F)
lines(time,Sq,type="l",col=pc[2],lty=2,lwd=3,axes=F)




#nc
yrange <- c(0,min(max(ENC,SNC),200))
plot(xrange,yrange,type="n", xlab="Time",
     ylab=TeX('$q_t$(not censored)'),cex.lab=1.6,xaxt='n' )
axis(1, at=1:4,labels=timee,font=2)
polygon(c(time,rev(time)),c(CINC[1,],rev(CINC[2,])),col =pc[3], border = FALSE)
lines(time,ENC,type="l",col=pc[1],lwd=3)
lines(time,SNC,type="l",col=pc[2],lty=2,lwd=3)

#First Title
text(line2user(line=mean(par('mar')[c(2, 4)]), side=2), 
     line2user(line=2, side=3), 'Targeted Moments', xpd=NA, cex=2, font=2)

#qr
yrange <- c(0,min(max(Eqr,Sqr),200))
plot(xrange,yrange,type="n", xlab="Time",
     ylab=TeX('$q^R_t$'),cex.lab=1.6,xaxt='n')
axis(1, at=1:4,labels=timee,font=2)
polygon(c(time,rev(time)),c(CIqr[1,],rev(CIqr[2,])),col =pc[3], border = FALSE)
lines(time,Eqr,type="l",col=pc[1],lwd=3)
lines(time,Sqr,type="l",col=pc[2],lty=2,lwd=3)



# m*Beta
xrange <- range(time)
yrange <- c(0,max(Embeta,Smbeta))
plot(xrange,yrange,type="n", xlab="Time",
     ylab=TeX('$m_t\\beta_t$'),cex.lab=1.6,xaxt='n')
axis(1, at=1:4,labels=timee,font=2)
polygon(c(time,rev(time)),c(CImbeta[1,],rev(CImbeta[2,])),col =pc[3], border = FALSE)
lines(time,Embeta,type="l",col=pc[1],lwd=3)
lines(time,Smbeta,type="l",col=pc[2],lty=2,lwd=3)


#Second Title
text(line2user(line=mean(par('mar')[c(2, 4)]), side=2), 
     line2user(line=2, side=3), 'Over-Identified moments', xpd=NA, cex=2, font=2)


# add an external legend
par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
legend("bottom", legend = c("Data", "Simulation"), 
       col=pc, lwd=2.5, cex=2, lty=c(1,2), horiz = TRUE,xpd=TRUE,bty = 'n',inset = c(0.1,0))
dev.off()



##########################################
# counterfactual experiment: no censorship
##########################################
SzC=numeric(length=4)
SmC=numeric(length=4)
SmbetaC=numeric(length=4)
SqcC=numeric(length=4)
SqrC=numeric(length=4)
SqC=numeric(length=4)
for(i in 1:4){
  
  SmC[i]=mt(0,p,i,max)
  SzC[i]=zt(0,p,i,max)
  SmbetaC[i]=mbetat(0,p,i,max)
  
  
  if(i>=2){
    
    SqcC[i]=qcs(0,p,i,max,mu,SqcC[i-1])
    SqrC[i]=qrs(0,p,i,max,mu,SqrC[i-1])
    SqC[i]=qs(0,p,i,max,mu,SqrC[i-1],SqcC[i-1])
  }else{
    
    SqcC[1]=Eqc[1]
    SqC[1]=Eq[1]
    SqrC[1]=Eqr[1]}}

# second graph to visualize the variables all at once
# set up something about the graph

pdf(file="dynamics.pdf", width = 10.3, height = 5)
par(mfrow=c(2,3),oma = c(3, 1, 1, 1),
    mai=c(0.5,0.5,0.5,0.5),
    mgp=c(2,0.3,0)) # all plots on one page 

# m*Beta
xrange <- range(time)
yrange <- c(0,max(SmbetaC,Smbeta))
plot(xrange,yrange,type="n", xlab="Time",
     ylab=TeX('$m_t\\beta_t$'),cex.lab=1.6,xaxt='n')
lines(time,Smbeta,type="l",col=pc[1],lwd=2)
lines(time,SmbetaC,type="l",col=pc[2],lty=2,lwd=2)
axis(1, at=1:4,labels=timee,font=2)

# m
yrange <- c(0,max(SmC,Sm))
plot(xrange,yrange,type="n", xlab="Time",
     ylab=TeX('$m_t$'),cex.lab=1.5,xaxt='n')
axis(1, at=1:4,labels=timee,font=2)
lines(time,Sm,type="l",col=pc[1],lwd=2)
lines(time,SmC,type="l",col=pc[2],lty=2,lwd=2)

# z
yrange <- c(0,min(max(SzC,Sz),200))
plot(xrange,yrange,type="n", xlab="Time",
     ylab=TeX('$z_t$'),cex.lab=1.5,xaxt='n')
axis(1, at=1:4,labels=timee,font=2)
lines(time,Sz,type="l",col=pc[1],lwd=2)
lines(time,SzC,type="l",col=pc[2],lty=2,lwd=2)

#q
yrange <- c(0,min(max(SqC,Sq),200))
plot(xrange,yrange,type="n", xlab="Time",
     ylab=TeX('$q_t$'),cex.lab=1.5,xaxt='n')
axis(1, at=1:4,labels=timee,font=2)
lines(time,Sq,type="l",col=pc[1],lwd=2)
lines(time,SqC,type="l",col=pc[2],lty=2,lwd=2)

#qr
yrange <- c(0,min(max(SqrC,Sqr),200))
plot(xrange,yrange,type="n", xlab="Time",
     ylab=TeX('$q^R_t$'),cex.lab=1.5,xaxt='n')
axis(1, at=1:4,labels=timee,font=2)
lines(time,Sqr,type="l",col=pc[1],lwd=2)
lines(time,SqrC,type="l",col=pc[2],lty=2,lwd=2)

#qc
yrange <- c(0,min(max(SqcC,Sqc),200))
plot(xrange,yrange,type="n", xlab="Time",
     ylab=TeX('$q^C_t$'),cex.lab=1.5,xaxt='n')
axis(1, at=1:4,labels=timee,font=2)
lines(time,Sqc,type="l",col=pc[1],lwd=2)
lines(time,SqcC,type="l",col=pc[2],lty=2,lwd=2)

# add an external legend
par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
legend("bottom", legend = c( "Simulation",TeX('$Countertfactual:\\beta_t=0$')), 
       col=pc, lwd=3, cex=2,horiz = TRUE,xpd=TRUE,bty = 'n',inset = c(0.1,0))
dev.off()




#Build the tables for the paper
sink("temp.Rnw")

cat(paste('\\begin{table}[H]
  \\centering % used for centering table
  \\begin{tabular}{@{} l c c c @{}}  
  \\hline\\hline %inserts double horizontal lines
  \\ External Parameters &  & Value & Target  \\\\ [0.05ex] % inserts table
    %heading
  \\hline % inserts single horizontal line
  \\rule{0pt}{2.5ex}
  Productivity of books  & $\\theta$   &',round(theta, digits=2),'& Variance of $q^R_1$  \\\\[0.15ex]
  Mean quality in 1  & $\\overline{q}_1$   &',round(Sq[1], digits=2),'& First period quality  \\\\[0.15ex]
  Mean rev. quality in 1  & $\\overline{q}^R_1$   &',round(Sqr[1], digits=2),'& First period quality \\\\[0.15ex]
  \\hline \\hline
  \\ Estimated Parameters &  & Value &  \\\\ [0.05ex] % inserts table
  \\hline
  \\ \\%censored revolutionary books  & $\\overline{\\beta}$   &',round(beta, digits=2),'& MSM  \\\\[0.15ex]
  TFP  & $(1+\\nu)\\mu$   &',round(mu, digits=2),'& MSM  \\\\[0.15ex]
  Price of compliant books   & $p$   &',round(p, digits=2),'& MSM  \\\\[0.15ex]
  \\hline
  \\end{tabular}
  \\end{table}'))

sink()
Sweave("temp.Rnw")





